{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análise de Dados da Fatal Model com PySpark\n",
        "## Sophia Katze de Paula, Jun/2025\n",
        "\n",
        "Este notebook apresenta a análise dos dados **users** e **user_transactions**, executando queries SQL via Pandas e PandaSQL, realizando uma simulação Monte Carlo de descontos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Imports e Setup\n",
        "\n",
        "Import das bibliotecas necessárias, bem como de ajuste nas tabelas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Carregamento Completo e Otimizado com Pandas\n",
        "# Autora: Sophia Katze de Paula – 2025-06-11\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pandasql import sqldf\n",
        "import os\n",
        "import sys\n",
        "import py7zr  \n",
        "\n",
        "# Configurações gerais\n",
        "pd.set_option('display.max_columns', None)\n",
        "sns.set_theme(style='whitegrid')\n",
        "\n",
        "#Unzip do Dataset\n",
        "py7zr.SevenZipFile(r'data/datasets.7z', mode='r').extractall(path=r'data/')\n",
        "\n",
        "# Carregando os dados \n",
        "df_transactions_raw = pd.read_csv(r'data/user_transaction_items_retificado2.csv')\n",
        "df_users_raw = pd.read_csv(r'data/users.csv')\n",
        "\n",
        "# Remover espaços dos nomes das colunas e converter para minúsculas\n",
        "df_transactions_raw.columns = df_transactions_raw.columns.str.replace(' ', '_').str.lower()\n",
        "df_users_raw.columns = df_users_raw.columns.str.replace(' ', '_').str.lower()\n",
        "\n",
        "\n",
        "# Exibir os novos nomes das colunas\n",
        "print(\"Colunas de df_items:\")\n",
        "print(df_transactions_raw.columns.tolist())\n",
        "\n",
        "print(\"\\nColunas de df_users:\")\n",
        "print(df_users_raw.columns.tolist())\n",
        "\n",
        "# Após carregar os DataFrames df_transaction e df_users:\n",
        "env_init = {\n",
        "    'transactions_raw': df_transactions_raw,\n",
        "    'users_raw': df_users_raw\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def exec_sql(sql_filename: str, env: dict) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Lê um arquivo .sql da pasta ../sql e executa a query via pandasql.\n",
        "\n",
        "    Args:\n",
        "        sql_filename (str): Nome do arquivo .sql (ex: '01_user_status.sql').\n",
        "        env (dict): Dicionário de DataFrames disponíveis para a query\n",
        "                    (ex: {'df_transacoes': df_transacoes, 'df_usuarios': df_usuarios}).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Resultado da consulta.\n",
        "    \"\"\"\n",
        "    # Monta o caminho completo relativo ao notebook em notebooks/\n",
        "    path = os.path.join('sql', sql_filename)\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        query = f.read()\n",
        "    # Executa a query no contexto dos DataFrames fornecidos\n",
        "    return sqldf(query, env)\n",
        "\n",
        "# Exemplo de uso:\n",
        "# env = {'df_transacoes': df_transacoes, 'df_usuarios': df_usuarios}\n",
        "# df_status = exec_sql('01_user_status.sql', env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Limpeza dos dados\n",
        "\n",
        "Tratamento de Null's e Duplicados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print nulls and duplicates for df_users_raw\n",
        "print(\"Nulls in df_users_raw:\")\n",
        "print(df_users_raw.isnull().sum())\n",
        "print(\"\\nDuplicates in df_users_raw:\")\n",
        "print(df_users_raw.duplicated().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print nulls and duplicates for df_transactions_raw  \n",
        "print(\"Nulls in df_transactions_raw:\")\n",
        "print(df_transactions_raw.isnull().sum())\n",
        "print(\"\\nDuplicates in df_transactions_raw:\")\n",
        "print(df_transactions_raw.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Executamos os SQL de limpeza\n",
        "df_transactions = exec_sql('clean_user_transactions.sql', env_init)\n",
        "df_users = exec_sql('clean_users.sql', env_init)\n",
        "\n",
        "# Após carregar os DataFrames df_transaction e df_users:\n",
        "env = {\n",
        "    'user_transactions': df_transactions,\n",
        "    'users': df_users\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print nulls and duplicates for df_users\n",
        "print(\"Nulls in df_users_raw:\")\n",
        "print(df_users_raw.isnull().sum())\n",
        "print(\"\\nDuplicates in df_users_raw:\")\n",
        "print(df_users_raw.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print nulls and duplicates for df_transactions\n",
        "print(\"Nulls in df_transactions:\")\n",
        "print(df_transactions.isnull().sum())\n",
        "print(\"\\nDuplicates in df_transactions:\")\n",
        "print(df_transactions.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Desafio 1.1: Taxa de Usuários por Status\n",
        "\n",
        "Qual a proporção de usuários ativos, onboarding, desabilitados e deletados?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executa arquivo sql/01_user_status.sql\n",
        "df_status = exec_sql('01_user_status.sql', env)\n",
        "df_status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Insight:** A saúde da base é medida por X% ativos e Y% banidos, direcionando estratégias de retenção e reengajamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Desafio 1.2: Padrão de Compras e Sazonalidade\n",
        "\n",
        "Como variam as compras e receita ao longo do tempo?## 3. Desafio 1.2: Padrão de Compras e Sazonalidade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executa arquivo sql/02_daily_sales.sql\n",
        "df_daily = exec_sql('02_daily_sales.sql', env)\n",
        "\n",
        "# Converte a coluna para datetime se necessário\n",
        "df_daily['data'] = pd.to_datetime(df_daily['data'])\n",
        "\n",
        "#Plotando\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(data=df_daily, x='data', y='receita')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Receita Diária')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.dates as mdates\n",
        "#O obejtivo é encontrar e indicar no gráfico max e min e respectivas datas\n",
        "\n",
        "# Encontra o valor máximo e mínimo\n",
        "max_row = df_daily.loc[df_daily['receita'].idxmax()]\n",
        "min_row = df_daily.loc[df_daily['receita'].idxmin()]\n",
        "\n",
        "# Plot principal\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(data=df_daily, x='data', y='receita')\n",
        "\n",
        "# Destaques\n",
        "plt.scatter([max_row['data']], [max_row['receita']], color='green', label='Máximo')\n",
        "plt.scatter([min_row['data']], [min_row['receita']], color='red', label='Mínimo')\n",
        "\n",
        "# Anotações\n",
        "plt.annotate(f\"Máx: {max_row['receita']:.0f}\\n{max_row['data'].date()}\",\n",
        "             xy=(max_row['data'], max_row['receita']),\n",
        "             xytext=(max_row['data'], max_row['receita'] * 1.05),\n",
        "             arrowprops=dict(arrowstyle=\"->\", color='green'),\n",
        "             color='green')\n",
        "\n",
        "plt.annotate(f\"Mín: {min_row['receita']:.0f}\\n{min_row['data'].date()}\",\n",
        "             xy=(min_row['data'], min_row['receita']),\n",
        "             xytext=(min_row['data'], min_row['receita'] * 1.3),\n",
        "             arrowprops=dict(arrowstyle=\"->\", color='red'),\n",
        "             color='red')\n",
        "\n",
        "# Eixo x formatado\n",
        "ax = plt.gca()\n",
        "ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
        "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Receita Diária')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Desafio 1.2.1: Agregado por Dia do Mês\n",
        "Quais dias do mês têm maior volume de vendas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Garante que a coluna 'data' está em datetime\n",
        "df_daily['data'] = pd.to_datetime(df_daily['data'])\n",
        "\n",
        "# Extrai o dia do mês\n",
        "df_daily['dia_do_mes'] = df_daily['data'].dt.day\n",
        "\n",
        "# Agrega receita média por dia do mês\n",
        "df_dia_mes = df_daily.groupby('dia_do_mes')['receita'].mean().reset_index()\n",
        "\n",
        "#Plot\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.barplot(data=df_dia_mes, x='dia_do_mes', y='receita', palette='viridis')\n",
        "\n",
        "plt.title('Receita Média por Dia do Mês (1 a 31)')\n",
        "plt.xlabel('Dia do Mês')\n",
        "plt.ylabel('Receita Média')\n",
        "plt.xticks(range(0, 31), [str(i+1) for i in range(31)])\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Desafio 1.2.2: Sazonalidade por Dias da Semana\n",
        "Há diferença de receita entre dias úteis e finais de semana?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executa SQL de vendas por dia da semana\n",
        "df_weekday = exec_sql('03_sales_by_weekday.sql', env)\n",
        "\n",
        "# Ordena corretamente os dias da semana em português\n",
        "dias_ordenados = ['Domingo', 'Segunda', 'Terça', 'Quarta', 'Quinta', 'Sexta', 'Sábado']\n",
        "df_weekday['dia_semana_nome'] = pd.Categorical(df_weekday['dia_semana_nome'], categories=dias_ordenados, ordered=True)\n",
        "df_weekday = df_weekday.sort_values('dia_semana_nome')\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=df_weekday, x='dia_semana_nome', y='receita', palette='crest')\n",
        "plt.title('Receita Total por Dia da Semana')\n",
        "plt.xlabel('Dia da Semana')\n",
        "plt.ylabel('Receita Total (mi. R$)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Posteriormente uma outra análise que é possível fazer é de Dias Normais x Feriado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Desafio 1.3: Usuários Pagantes e ARPU\n",
        "\n",
        "Quantos usuários pagam e quanto em média gastam?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executa arquivo sql/04_spend_per_user.sql\n",
        "df_arpu = exec_sql('04_spend_per_user.sql', env)\n",
        "df_arpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Desafio 1.4: Faturamento Mensal\n",
        "\n",
        "Qual a performance de receita mês a mês?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executa arquivo sql/05_monthly_revenue.sql\n",
        "df_monthly = exec_sql('05_monthly_revenue.sql', env)\n",
        "\n",
        "# Criar gráfico de linha mensal\n",
        "plt.figure(figsize=(14,6))\n",
        "sns.lineplot(data=df_monthly, x='mes_ano', y='receita', marker='o', linewidth=2)\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Receita Mensal', fontsize=14)\n",
        "plt.xlabel('Mês/Ano', fontsize=12)\n",
        "plt.ylabel('Receita Total (mi. R$)', fontsize=12)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Desafio 2.1: Identificação da Promoção\n",
        "\n",
        "Quando ocorreu a promoção de 85% de desconto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executa arquivo sql/06_promotion_period.sql\n",
        "df_promo = exec_sql('06_promotion_period.sql', env)\n",
        "\n",
        "df_promo['data']=pd.to_datetime(df_promo['data'])\n",
        "\n",
        "# Define o início e fim do período promocional\n",
        "inicio_promocao = df_promo['data'].min()\n",
        "fim_promocao = df_promo['data'].max()\n",
        "\n",
        "print(f\"Início da promoção: {inicio_promocao.date()}\")\n",
        "print(f\"Fim da promoção: {fim_promocao.date()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Desafio 2.2: Impacto da Promoção\n",
        "\n",
        "Como a receita e o número de transações mudaram?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Executa arquivo sql/06_promotion_impact.sql\n",
        "df_impact = exec_sql('06_promotion_impact.sql', env)\n",
        "df_impact"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Desafio 2.3: Simulação Monte Carlo de Desconto Ideal\n",
        "\n",
        "Executamos a simulação para recomendar desconto ideal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts import promo_simulation\n",
        "\n",
        "#from scripts.promo_simulation import simular_receita_descontos, plotar_simulacao\n",
        "periodo = (df_promo['data'].min(), df_promo['data'].max())\n",
        "df_sim = simular_receita_descontos(df_transacoes, periodo, list(range(0,91,10)), n_sim=3000)\n",
        "plotar_simulacao(df_sim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Conclusão e Próximos Passos\n",
        "\n",
        "- Resumo dos principais insights.\n",
        "- Ações recomendadas: testes de descontos moderados, monitoramento contínuo via Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
